
const tokenizers = @[]
  @{} name: 'comment_eol', kind:'//', open: /\/\//, close: /.*($)/
  @{} name: 'comment_multi', kind:'/*', open: /\/\*/, close: /.*?(\*\/|$)/, multiline: true
  @{} name: 'str_single', kind:"'", open: /'/, close: /(?:\\.|[^'])*(')/
  @{} name: 'str_double', kind:'"', open: /"/, close: /(?:\\.|[^"])*(")/
  @{} name: 'str_multi', kind:'`', open: /`/, close: /(?:\\.|[^`])*(`|$)/, multiline: true
  @{} name: 'empty_line', kind:'', open: /^/, close: /\s*($)/

const rx_tokens = new RegExp @
  tokenizers
    .map @ e => `(?:(${e.open.source})${e.close.source})`
    .join('|')
  'g'

tokenizers.multiline = {}
tokenizers.kind = {}

::
  for const each of tokenizers ::
    tokenizers.kind[each.kind] = each
    tokenizers.kind[each.name] = each
    if each.multiline ::
      tokenizers.multiline[each.kind] = each


const rx_offside = /\B(::()|::{}|::[]|::|@()|@{}|@[]|@:|@#|@|)\B/

transform_jsy.func = function (func) ::
  return transform_jsy @ func.toString()
transform_jsy.file = function(filename) ::
  return new Promise @ (resolve, reject) =>
    fs.readFile @ filename, 'utf8', (err, src) =>
      err ? reject(err) : resolve @ transform_jsy @ src, filename

export default transform_jsy
async function transform_jsy(src, filename) ::
  const lines = src.split(/\r\n|\r|\n/)
    .map @ (src, idx) => @:
      src, pos: @{} line: 1+idx, //filename

  tokenize @ lines[0]
  lines.reduce @ (a, b) => ::
    tokenize @ b, a.tkn_continue
    return b

  return lines


function tokenize(entry, tkn_continue) ::
  let sz0=0, {src} = entry
  const src_orig=src, shadow = entry.shadow = []

  if null == tkn_continue ::
    entry.indent = src.match(/^\s*/)[0]
  else ::
    entry.indent = false
    src = src.replace @ tkn_continue.close, (match, ...args) => ::
      shadow.push @ 0, match.length, tkn_continue.name
      return ''
    if '' === src ::
      entry.tkn_continue = tkn_continue
      entry.skip = true
      return
    sz0 = src_orig.length - src.length

  src.replace @ rx_tokens, map_shadows
  return entry

  function map_shadows(match, ...pairs) ::
    const src = pairs.pop()
    const pos = pairs.pop()
    pairs = pairs.filter @ e=> undefined !== e

    if pairs.length !== 2 ::
      throw new Error @ 'Pair mismatch'

    if ! pairs[1] ::
      const tkn_continue = tokenizers.multiline[pairs[0]]
      if tkn_continue ::
        entry.tkn_continue = tkn_continue

      if ! pairs[0] ::
        entry.skip = true
        entry.indent = false
        return match // no-op

    const s = sz0 + pos, e = s+match.length, orig = src_orig.slice(s,e)
    if match != orig ::
      throw new Error @ `Slice mismatch (s:${s} e:${e} m:"${match}" orig:"${orig}")`
    shadow.push @ s,e, tokenizers.kind[pairs[0]].name
    return match // no-op


